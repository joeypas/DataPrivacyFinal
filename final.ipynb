{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "daa5f479",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\n# Some useful utilities\n\ndef laplace_mech(v, sensitivity, epsilon):\n    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n\ndef gaussian_mech(v, sensitivity, epsilon, delta):\n    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n\ndef gaussian_mech_vec(v, sensitivity, epsilon, delta):\n    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon, size=len(v))\n\ndef pct_error(orig, priv):\n    return np.abs(orig - priv)/orig * 100.0\n\ndef z_clip(xs, b):\n    return [min(x, b) for x in xs]\n\ndef g_clip(v):\n    n = np.linalg.norm(v, ord=2)\n    if n > 1:\n        return v / n\n    else:\n        return v"
        },
        {
            "cell_type": "markdown",
            "id": "9863db49",
            "metadata": {},
            "source": "# Setup\nHere we want to load our dataset, preprocessing, and split into train and test for our model"
        },
        {
            "cell_type": "markdown",
            "id": "66a4c14e",
            "metadata": {},
            "source": "## Step 1: load the data"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "304beb6c",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "default_of_credit_clients = pd.read_csv(\"default_of_credit_card_clients.csv\")\n\ncols = default_of_credit_clients.iloc[0].tolist()\ncols[-1] = \"default\"\n\ndf = default_of_credit_clients[1:].copy()\ndf.columns = cols\n\ndf = df.apply(pd.to_numeric, errors=\"coerce\")"
        },
        {
            "cell_type": "markdown",
            "id": "6e3272d8",
            "metadata": {},
            "source": "## Step 2: Split train/test data"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "581ca9f5",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "from sklearn.model_selection import train_test_split\n\nX = df.drop(columns=[\"default\"]).reset_index(drop=True)\ny = df[\"default\"].astype(int)\n\nassert isinstance(X, pd.DataFrame)\nassert isinstance(y, pd.Series)\n\nX = X.reset_index(drop=True)\ny = y.reset_index(drop=True)\n\ntraining_size = int(X.shape[0] * 0.8)\n\nX_train = X.iloc[:training_size]\nX_test = X.iloc[training_size:]\n\ny_train = y.iloc[:training_size]\ny_test = y.iloc[training_size:]"
        },
        {
            "cell_type": "markdown",
            "id": "507c90ec",
            "metadata": {},
            "source": "## Step 3: Convert X_train/X_test to StandardScaler"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "489c44de",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)"
        },
        {
            "cell_type": "markdown",
            "id": "6487153a",
            "metadata": {},
            "source": "## Step 4: Convert to numpy"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "56ea601c",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "X_train = X_train_scaled.astype(float)\nX_test = X_test_scaled.astype(float)\n\ny_train = y_train.to_numpy().astype(float)\ny_test = y_test.to_numpy().astype(float)"
        },
        {
            "cell_type": "markdown",
            "id": "a2aa49fe",
            "metadata": {},
            "source": "# Using Scikit-Learn\nThis is going to be our baseline model that we want to compare against a \ndifferentially private gradient descent model"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "abcd56c7",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1., 0., 0., ..., 1., 0., 0.], shape=(6000,))"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(max_iter=20000).fit(X_train, y_train)\nmodel.predict(X_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "6466a95f",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "np.float64(0.821)"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "np.sum(model.predict(X_test) == y_test)/X_test.shape[0]"
        },
        {
            "cell_type": "markdown",
            "id": "0c55c567",
            "metadata": {},
            "source": "# Model Prediction"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "5d7dd0dd",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "theta = np.zeros(X_train.shape[1])\n\ndef predict(xi, theta, bias=0):\n    label = np.sign(xi @ theta + bias)\n    return label\n\ndef accuracy(theta):\n    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]"
        },
        {
            "cell_type": "markdown",
            "id": "b10b5f7b",
            "metadata": {},
            "source": "# Gradient Descent Model"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "e9701d85",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "def loss(theta, xi, yi):\n    exponent = - yi * (xi.dot(theta))\n    return np.log(1 + np.exp(exponent))"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "9148db15",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "np.float64(0.6931471805599454)"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "np.mean([loss(theta, x_i, y_i) for x_i, y_i in zip(X_test, y_test)])"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "adac883e",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "np.float64(0.15266666666666667)"
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "def logistic(x):\n    return 1 / (1 + np.exp(-x))\n\n\ndef gradient(theta, xi, yi):\n    z = yi * np.dot(xi, theta)\n\n    if z >= 0:\n        exp_neg_z = np.exp(-z)\n        sigma = 1 / (1 + exp_neg_z)\n    else:\n        exp_z = np.exp(z)\n        sigma = exp_z / (1 + exp_z)\n\n    return -yi * xi * (1 - sigma)\n\ndef avg_grad(theta, X, y):\n    grads = [gradient(theta, xi, yi) for xi, yi in zip(X, y)]\n    return np.mean(grads, axis=0)\n\ndef gradient_descent(iterations):\n    theta = np.zeros(X_train.shape[1])\n\n    for _ in range(iterations):\n        theta = theta - avg_grad(theta, X_train, y_train)\n\n    return theta\n\ntheta = gradient_descent(10)\naccuracy(theta)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}